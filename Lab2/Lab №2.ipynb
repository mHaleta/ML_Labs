{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторна робота №2. Методи класифікації\n",
    "## Виконав студент групи КМ-91мп\n",
    "## Галета М.С.\n",
    "## Завдання на лабораторну роботу\n",
    "<img src=\"task1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зчитування датасету та його розбиття на тренувальну та відкладену вибірки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('MP-04-Galeta.csv', sep=';', names=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'y'])\n",
    "\n",
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Побудова дерева рішень"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self, parent=None):\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.splitFeature = None\n",
    "        self.splitFeatureValue = None\n",
    "        self.label = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataToDistribution(data):\n",
    "    ''' Функція перетворює набір даних, який має n можливих\n",
    "        класифікаційних міток, в розподіл ймовірностей з n записами. '''\n",
    "    \n",
    "    allLabels = [label for (point, label) in data]\n",
    "    numEntries = len(allLabels)\n",
    "    possibleLabels = set(allLabels)\n",
    "    dist= []\n",
    "    for aLabel in possibleLabels:\n",
    "        dist.append(float(allLabels.count(aLabel)) / numEntries)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(dist):\n",
    "    ''' Функція обчислює ентропію Шеннона для заданого розподілу ймовірностей. '''\n",
    "    return -sum([p * math.log(p, 2) for p in dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(data, featureIndex):\n",
    "    ''' Функція виконує ітерацію над підмножинами даних,\n",
    "        що відповідають кожному значенню функції в індексі featureIndex.'''\n",
    "    \n",
    "    # отримання можливих значень заданої ознаки\n",
    "    attrValues= [point[featureIndex] for (point, label) in data]\n",
    "    for aValue in set(attrValues):\n",
    "        # обчислення частини розбиття, що відповідає обраному значенню\n",
    "        dataSubset= [(point, label) for (point, label) in data if point[featureIndex] == aValue]\n",
    "        yield dataSubset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(data, featureIndex):\n",
    "    ''' Функція обчислює очікуваний приріст інформації від\n",
    "        розбиття даних на всі можливі значення функції '''\n",
    "    \n",
    "    entropyGain = entropy(dataToDistribution(data))\n",
    "    for dataSubset in splitData(data, featureIndex):\n",
    "        entropyGain -= entropy(dataToDistribution(dataSubset))\n",
    "    return entropyGain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homogeneous(data):\n",
    "    ''' Функція повертає True, якщо дані мають однакову мітку,\n",
    "        і False в іншому випадку '''\n",
    "    return len(set([label for (point, label) in data])) <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorityVote(data, node):\n",
    "    ''' Функція повертає вузол мітки з більшістю міток класу в даному наборі даних '''\n",
    "    \n",
    "    labels = [label for (point, label) in data]\n",
    "    choice = max(set(labels), key=labels.count)\n",
    "    node.label= choice\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDecisionTree(data, root, remainingFeatures, max_depth):\n",
    "    ''' Функція будує дерево рішень з даних даних,\n",
    "        додаючи дітей до кореневого вузла (який може бути піддеревом) '''\n",
    "    \n",
    "    # Глобальна змінна, яка позначає поточну глибину дерева\n",
    "    global current_depth\n",
    "    \n",
    "    # Зупиняємось, якщо поточна глибина більша за максимально допустиму глибину дерева\n",
    "    if current_depth >= max_depth:\n",
    "        remainingFeatures = []\n",
    "    \n",
    "    # Якщо всі елементи мають однаковий клас, то класифікуємо листок дерева міткою цього класу\n",
    "    if homogeneous(data):\n",
    "        root.label= data[0][1]\n",
    "        root.classCounts = {root.label: len(data)}\n",
    "        return root\n",
    "    \n",
    "    # Якщо немає більше ознак для подальшого розбиття, \n",
    "    # то класифікуємо листок дерева міткою класу якого більшість\n",
    "    if len(remainingFeatures) == 0:\n",
    "        return majorityVote(data, root)\n",
    "    \n",
    "    # Знаходження індексу найкращої функції для поділу\n",
    "    bestFeature= max(remainingFeatures, key=lambda index: gain(data, index))\n",
    "    # Якщо приріст інформації дорівнює нулю,\n",
    "    # то класифікуємо листок дерева міткою класу якого більшість\n",
    "    if gain(data, bestFeature) == 0:\n",
    "        return majorityVote(data, root)\n",
    "    \n",
    "    root.splitFeature = bestFeature\n",
    "    \n",
    "    #Додавання дочірніх вузлів для вже існуючих\n",
    "    for dataSubset in splitData(data, bestFeature):\n",
    "        aChild = Tree(parent=root)\n",
    "        aChild.splitFeatureValue = dataSubset[0][0][bestFeature]\n",
    "        root.children.append(aChild)\n",
    "        \n",
    "        #Запуск рекурсивного процесу, де дочірні вузли виступають в якості батьківського вузла\n",
    "        buildDecisionTree(dataSubset, aChild, remainingFeatures - set([bestFeature]), max_depth)\n",
    "        \n",
    "    current_depth += 1\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(data, max_depth):\n",
    "    ''' Функція повертає збудоване дерево '''\n",
    "    return buildDecisionTree(data, Tree(), set(range(len(data[0][0]))), max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, point):\n",
    "    ''' Функція класифікаці даних шляхом проходження даного дерева рішень. '''\n",
    "    if tree.children== []:\n",
    "        return tree.label\n",
    "    else:\n",
    "        matchingChildren = []\n",
    "        for child in tree.children:\n",
    "            if child.splitFeatureValue == point[tree.splitFeature]:\n",
    "                matchingChildren.append(child)\n",
    "                \n",
    "        try:\n",
    "            return classify(matchingChildren[0], point)\n",
    "        except Exception:\n",
    "            return child.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оцінювання якості збудованого дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= max_depth - 2 =============\n",
      "Train accuracy: 44.23 %\n",
      "Test accuracy: 23.076923076923077 %\n",
      "\n",
      "============= max_depth - 3 =============\n",
      "Train accuracy: 44.23 %\n",
      "Test accuracy: 23.076923076923077 %\n",
      "\n",
      "============= max_depth - 4 =============\n",
      "Train accuracy: 44.23 %\n",
      "Test accuracy: 23.076923076923077 %\n",
      "\n",
      "============= max_depth - 5 =============\n",
      "Train accuracy: 44.23 %\n",
      "Test accuracy: 23.076923076923077 %\n",
      "\n",
      "============= max_depth - 6 =============\n",
      "Train accuracy: 46.15 %\n",
      "Test accuracy: 15.384615384615385 %\n",
      "\n",
      "============= max_depth - 7 =============\n",
      "Train accuracy: 46.15 %\n",
      "Test accuracy: 15.384615384615385 %\n",
      "\n",
      "============= max_depth - 8 =============\n",
      "Train accuracy: 57.69 %\n",
      "Test accuracy: 0.0 %\n",
      "\n",
      "============= max_depth - 9 =============\n",
      "Train accuracy: 63.46 %\n",
      "Test accuracy: 0.0 %\n",
      "\n",
      "============= max_depth - 10 =============\n",
      "Train accuracy: 63.46 %\n",
      "Test accuracy: 0.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = [(x[:-1], x[-1]) for x in X_train.values.tolist()]\n",
    "test_data = [(x[:-1], x[-1]) for x in X_test.values.tolist()]\n",
    "\n",
    "y_train = np.array([label for point, label in train_data])\n",
    "y_test = np.array([label for point, label in test_data])\n",
    "\n",
    "for max_depth in range(2, 11):\n",
    "    current_depth = 0\n",
    "    tree = decisionTree(train_data, max_depth=max_depth)\n",
    "\n",
    "    y_predicted_train = [classify(tree, point) for point, label in train_data]\n",
    "    y_predicted_test = [classify(tree, point) for point, label in test_data]\n",
    "    \n",
    "    accuracy_test = (y_predicted_test == y_test).mean()\n",
    "    accuracy_train = (y_predicted_train == y_train).mean()\n",
    "    \n",
    "    print('============= max_depth -', max_depth, '=============')\n",
    "    print('Train accuracy:',np.round(accuracy_train*100,2),'%')\n",
    "    print('Test accuracy:',accuracy_test*100,'%')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отже, при глибині дерева 2, 3, 4 або 5 воно найкраще класифікує відкладену вибірку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(x[:-1], x[-1]) for x in X_train.values.tolist()]\n",
    "test_data = [(x[:-1], x[-1]) for x in X_test.values.tolist()]\n",
    "\n",
    "y_train = np.array([label for point, label in train_data])\n",
    "y_test = np.array([label for point, label in test_data])\n",
    "\n",
    "current_depth = 0\n",
    "tree = decisionTree(train_data, max_depth=4)\n",
    "\n",
    "y_predicted_train = [classify(tree, point) for point, label in train_data]\n",
    "y_predicted_test = [classify(tree, point) for point, label in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(y_test)) \n",
    "width = 0.3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.bar(x - width/2, y_test, width, label='true labels')\n",
    "ax.bar(x + width/2, y_predicted_test, width, label='predicted labels')\n",
    "\n",
    "ax.set_ylabel('Class label')\n",
    "ax.set_xticks(x)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train[X_train.columns[0:-1]].values\n",
    "y_train = X_train[X_train.columns[-1]].values\n",
    "x_test = X_test[X_test.columns[0:-1]].values\n",
    "y_test = X_test[X_test.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(x_known, x_unknown):\n",
    "    \n",
    "    num_pred = x_unknown.shape[0]\n",
    "    num_data = x_known.shape[0]\n",
    "    \n",
    "    dists = np.zeros((num_pred, num_data))\n",
    "\n",
    "    for i in range(num_pred):\n",
    "        for j in range(num_data):\n",
    "            dists[i,j] = np.sum(x_known[j] == x_unknown[i])\n",
    "            \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_labels(dists, y_known, k):\n",
    "        \n",
    "    num_pred = dists.shape[0]\n",
    "    n_nearest = []\n",
    "    \n",
    "    for j in range(num_pred):\n",
    "        dst = dists[j]\n",
    "        closest_y = y_known[np.argpartition(dst, k-1)[:k]]\n",
    "        \n",
    "        n_nearest.append(closest_y)\n",
    "        \n",
    "    return np.asarray(n_nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearest_Neighbours:\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.test_set_x = None\n",
    "        self.train_set_x = None\n",
    "        self.train_set_y = None\n",
    "\n",
    "        \n",
    "    def fit(self, train_set_x, train_set_y):\n",
    "        self.train_set_x = train_set_x\n",
    "        self.train_set_y = train_set_y\n",
    "        \n",
    "    def predict(self, test_set_x):\n",
    "\n",
    "        y_labels = k_nearest_labels(compute_distances(self.train_set_x, test_set_x), self.train_set_y, self.k)\n",
    "        y_predictions = []\n",
    "        for i in range(y_labels.shape[0]):\n",
    "            bc = np.bincount(y_labels[i])\n",
    "            y_predictions.append(np.arange(len(bc))[bc == bc.max()].min())\n",
    "        \n",
    "        return y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1; accuracy = 7.6923076923076925%\n",
      "k = 3; accuracy = 15.384615384615385%\n",
      "k = 5; accuracy = 15.384615384615385%\n",
      "k = 7; accuracy = 15.384615384615385%\n",
      "k = 9; accuracy = 7.6923076923076925%\n"
     ]
    }
   ],
   "source": [
    "for k in range(1, 10, 2):\n",
    "    knn = KNearest_Neighbours(k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred_knn = knn.predict(x_test)\n",
    "    accuracy = (y_pred_knn == y_test).mean() * 100\n",
    "    print(\"k = {}; accuracy = {}%\".format(k, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### З даних результатів видно, що для даного набору даних кількість сусідів, при якій алгоритм дає найбільшу точність, дорівнює 3, 5 або 7. Гірша точність при К = 1 або 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNearest_Neighbours(5)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred_knn = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "К найближчих сусідів:     [10, 10, 10, 10, 13, 10, 13, 8, 10, 13, 9, 9, 10]\n",
      "Дерева прийняття рішень:  [11, 10, 11, 11, 11, 10, 11, 11, 10, 11, 13, 14, 11]\n"
     ]
    }
   ],
   "source": [
    "print(\"К найближчих сусідів:    \",y_pred_knn)\n",
    "print(\"Дерева прийняття рішень: \",y_predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кількість однаково спрогнозованих значень двома методами:  3\n"
     ]
    }
   ],
   "source": [
    "print(\"Кількість однаково спрогнозованих значень двома методами: \",sum(np.array(y_predicted_test) == (y_pred_knn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Висновки\n",
    "##### 1) Було реалізовано два методи класифікації: дерево прийняття рішень та KNN\n",
    "##### 2) В ході роботи було встановлено, що дерево прийняття рішень дає кращий результат на відкладеній вибірці, ніж KNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
